{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123188f54b1194a",
   "metadata": {},
   "source": [
    "## Loading the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6467a93d522016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:48.960565Z",
     "start_time": "2024-05-14T13:38:48.957524Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bd0547c8a1f04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:49.030986Z",
     "start_time": "2024-05-14T13:38:49.018588Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2f1d5b31964ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:49.036682Z",
     "start_time": "2024-05-14T13:38:49.033006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n",
      "Data [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "Target [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = iris.data[:, :4] \n",
    "Y = iris.target \n",
    "feature_size = len(iris.feature_names)\n",
    "print(iris.target_names)\n",
    "target_size = 1\n",
    "print(\"Data\",X)\n",
    "print(\"Target\",Y)\n",
    "print(type(X),type(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00e4f6e4f6bf483",
   "metadata": {},
   "source": [
    "## Splitting the dataset intro train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17f828c9244d3c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:49.041859Z",
     "start_time": "2024-05-14T13:38:49.037710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.20,random_state = 42) \n",
    "print(type(X_train),type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fd7d726d8439e",
   "metadata": {},
   "source": [
    "## Learning with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b975969b36febcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:49.047387Z",
     "start_time": "2024-05-14T13:38:49.042865Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_mas.head import Head\n",
    "from torch_mas.data import DataBuffer\n",
    "\n",
    "model = Head(\n",
    "    feature_size, \n",
    "    target_size, \n",
    "    R=0.25,\n",
    "    imprecise_th=0.5,\n",
    "    bad_th=0.0015,\n",
    "    alpha=0.5,\n",
    "    memory_length=3,\n",
    "    n_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e762f9ad0bb829",
   "metadata": {},
   "source": [
    "## Training the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba646631d02b8e5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:50.052171Z",
     "start_time": "2024-05-14T13:38:49.052393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0.5208055973052979s\n",
      "Number of agents created: 97\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "dataset = DataBuffer(X_train,y_train)\n",
    "t = time.time()\n",
    "model.fit(dataset)\n",
    "tt = time.time() - t\n",
    "print(f\"Total training time: {tt}s\")\n",
    "\n",
    "print(\"Number of agents created:\", model.agents.n_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee5b5cc3a50af2",
   "metadata": {},
   "source": [
    "## Computing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175936dbd3b66c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:50.056021Z",
     "start_time": "2024-05-14T13:38:50.053177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a353c4258c44b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:38:50.067037Z",
     "start_time": "2024-05-14T13:38:50.056021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction time: 0.0031893253326416016s for 4 samples\n",
      "Prediction time per sample: 2.657771110534668e-05s\n",
      "tensor([False,  True,  True, False,  True, False,  True,  True,  True, False,\n",
      "         True, False, False, False, False,  True,  True, False,  True,  True,\n",
      "        False, False, False,  True,  True,  True,  True,  True, False, False])\n",
      "Differences: 16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import math\n",
    "test_feature_size = X_test.size\n",
    "t = time.time()\n",
    "y_pred = model.predict(torch.from_numpy(X_test).float()).round()\n",
    "y_test = torch.from_numpy(y_test).int()\n",
    "tt = time.time() - t\n",
    "tps = tt / test_feature_size\n",
    "print(f\"Total Prediction time: {tt}s for 4 samples\")\n",
    "print(f\"Prediction time per sample: {tps}s\")\n",
    "\n",
    "differences = torch.ne(y_pred.squeeze(), y_test)\n",
    "print(differences)\n",
    "num_differences = differences.sum().item()\n",
    "        \n",
    "print(\"Differences:\", num_differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8813eb3aa6710",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f989949ece811e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T13:48:52.331407Z",
     "start_time": "2024-05-14T13:38:50.068057Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m dataset \u001b[38;5;241m=\u001b[39m DataBuffer(X_train,y_train)\n\u001b[0;32m     23\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(X_test)\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mround()\n\u001b[0;32m     27\u001b[0m differences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mne(y_pred\u001b[38;5;241m.\u001b[39msqueeze(), y_test)\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_mas-0.1-py3.11.egg\\torch_mas\\head.py:138\u001b[0m, in \u001b[0;36mHead.fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs:\n\u001b[0;32m    137\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m dataset[torch\u001b[38;5;241m.\u001b[39mLongTensor([idx])]\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_mas-0.1-py3.11.egg\\torch_mas\\head.py:111\u001b[0m, in \u001b[0;36mHead.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    109\u001b[0m         agents_to_update \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([agents_to_update, created_idxs])\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_activated \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 111\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivated_agents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore(predictions, y)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (n_predictions,)\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     activated_maturity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents\u001b[38;5;241m.\u001b[39mmaturity(activated_agents)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_mas-0.1-py3.11.egg\\torch_mas\\agents.py:180\u001b[0m, in \u001b[0;36mAgents.predict\u001b[1;34m(self, X, agents_idxs)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mFloatTensor, agents_idxs: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mBoolTensor\n\u001b[0;32m    170\u001b[0m ):\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve predictions from agents\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m        Tensor: (n_agents, batch_size, output_dim)\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_predict_linear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43magents_idxs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_mas-0.1-py3.11.egg\\torch_mas\\linear_models.py:71\u001b[0m, in \u001b[0;36mbatch_predict_linear_regression\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_predict_linear_regression\u001b[39m(X, parameters):\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a linear transformation with a batch of parameters\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m        Tensor: (n_parameter_set, batch_size, output_dim)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_batch_predict_linear_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\apis.py:188\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\vmap.py:281\u001b[0m, in \u001b[0;36mvmap_impl\u001b[1;34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(func, flat_in_dims, chunks_flat_args,\n\u001b[0;32m    278\u001b[0m                          args_spec, out_dims, randomness, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\vmap.py:47\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[1;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_functorch\\vmap.py:403\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[1;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[0;32m    402\u001b[0m     batched_inputs \u001b[38;5;241m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[1;32m--> 403\u001b[0m     batched_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch_mas-0.1-py3.11.egg\\torch_mas\\linear_models.py:53\u001b[0m, in \u001b[0;36mpredict_linear_regression\u001b[1;34m(X, parameters)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_linear_regression\u001b[39m(X, parameters):\n\u001b[0;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a linear transformation\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m        Tensor: (batch_size, output_dim)\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m parameters\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dic = {\n",
    "    \"R\" : {0,1},\n",
    "    \"bad_th\" : {0,1},\n",
    "    \"alpha\" : {0,1},\n",
    "}\n",
    "init = 0.1\n",
    "best = math.inf\n",
    "bestdic = []\n",
    "for R in range(1,10):\n",
    "    for b in range(1,10):\n",
    "        for a in range(1,10):\n",
    "            model = Head(\n",
    "            feature_size, \n",
    "            target_size, \n",
    "            R=R*init,\n",
    "            imprecise_th=0.5,\n",
    "            bad_th=b*init,\n",
    "            alpha=a*init,\n",
    "            memory_length=3,\n",
    "            n_epochs=5\n",
    "            )\n",
    "            dataset = DataBuffer(X_train,y_train)\n",
    "            t = time.time()\n",
    "            model.fit(dataset)\n",
    "            y_pred = model.predict(torch.from_numpy(X_test).float()).round()\n",
    "            \n",
    "            differences = torch.ne(y_pred.squeeze(), y_test)\n",
    "            num_differences = differences.sum().item()\n",
    "            #print(\"Parameters : \",R*init,\":\",b*init,\":\",a*init,\" Score:\",num_differences)\n",
    "            if(num_differences < best):\n",
    "                bestdic = [{R,b,a}]\n",
    "                best = num_differences\n",
    "            elif num_differences == best:\n",
    "                bestdic.append({R,b,a})\n",
    "print(\"Best parameters\", bestdic, \" with Score\", best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
