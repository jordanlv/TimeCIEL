{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the iris dataset",
   "id": "123188f54b1194a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.043709Z",
     "start_time": "2024-05-14T11:17:21.040012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "7b6467a93d522016",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.093786Z",
     "start_time": "2024-05-14T11:17:21.088717Z"
    }
   },
   "cell_type": "code",
   "source": "iris = datasets.load_iris()",
   "id": "97bd0547c8a1f04f",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.098267Z",
     "start_time": "2024-05-14T11:17:21.094792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = iris.data[:, :4] \n",
    "Y = iris.target \n",
    "feature_size = len(iris.feature_names)\n",
    "target_size = len(iris.target_names)"
   ],
   "id": "da2f1d5b31964ec8",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting the dataset intro train and test",
   "id": "e00e4f6e4f6bf483"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.102915Z",
     "start_time": "2024-05-14T11:17:21.099274Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.20,random_state = 42) ",
   "id": "17f828c9244d3c34",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Learning with Context",
   "id": "ce4fd7d726d8439e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.109435Z",
     "start_time": "2024-05-14T11:17:21.103922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_mas.head import Head\n",
    "from torch_mas.data import DataBuffer\n",
    "\n",
    "model = Head(\n",
    "    feature_size, \n",
    "    target_size, \n",
    "    R=0.5,\n",
    "    imprecise_th=0.01,\n",
    "    bad_th=0.1,\n",
    "    alpha=0.1,\n",
    "    memory_length=10,\n",
    "    n_epochs=3\n",
    ")"
   ],
   "id": "6b975969b36febcd",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the agents",
   "id": "40e762f9ad0bb829"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.890651Z",
     "start_time": "2024-05-14T11:17:21.110441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "dataset = DataBuffer(X_train,y_train)\n",
    "t = time.time()\n",
    "model.fit(dataset)\n",
    "tt = time.time() - t\n",
    "print(f\"Total training time: {tt}s\")\n",
    "\n",
    "print(\"Number of agents created:\", model.agents.n_agents)"
   ],
   "id": "ba646631d02b8e5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 0.7769994735717773s\n",
      "Number of agents created: 65\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Computing performance",
   "id": "44ee5b5cc3a50af2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.894933Z",
     "start_time": "2024-05-14T11:17:21.891658Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(X_test))",
   "id": "175936dbd3b66c48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.926010Z",
     "start_time": "2024-05-14T11:17:21.895944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "test_feature_size = X_test.size\n",
    "t = time.time()\n",
    "y_pred = model.predict(torch.from_numpy(X_test).float())\n",
    "y_test = torch.from_numpy(y_test).int()\n",
    "tt = time.time() - t\n",
    "tps = tt / test_feature_size\n",
    "print(f\"Total Prediction time: {tt}s for 4 samples\")\n",
    "print(f\"Prediction time per sample: {tps}s\")\n",
    "print(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "\n",
    "mse = ((y_pred - y_test) ** 2).mean()\n",
    "print(\"Mean Squared Error:\", mse.detach().numpy())"
   ],
   "id": "f1a353c4258c44b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Prediction time: 0.006001710891723633s for 4 samples\n",
      "Prediction time per sample: 5.0014257431030275e-05s\n",
      "[[6.1 2.8 4.7 1.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [4.8 3.1 1.6 0.2]]\n",
      "tensor([[1.0334, 1.0334, 1.0334],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [2.0197, 2.0197, 2.0197],\n",
      "        [1.2954, 1.2954, 1.2954],\n",
      "        [1.1561, 1.1561, 1.1561],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [1.0168, 1.0168, 1.0168],\n",
      "        [1.9581, 1.9581, 1.9581],\n",
      "        [1.7779, 1.7779, 1.7779],\n",
      "        [0.9910, 0.9910, 0.9910],\n",
      "        [1.5901, 1.5901, 1.5901],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [1.0765, 1.0765, 1.0765],\n",
      "        [1.9893, 1.9893, 1.9893],\n",
      "        [0.9962, 0.9962, 0.9962],\n",
      "        [1.1543, 1.1543, 1.1543],\n",
      "        [1.9562, 1.9562, 1.9562],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [1.7089, 1.7089, 1.7089],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [1.9476, 1.9476, 1.9476],\n",
      "        [   nan,    nan,    nan],\n",
      "        [2.0002, 2.0002, 2.0002],\n",
      "        [1.9613, 1.9613, 1.9613],\n",
      "        [2.0665, 2.0665, 2.0665],\n",
      "        [0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000]], grad_fn=<DivBackward0>)\n",
      "tensor([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2, 0, 2,\n",
      "        2, 2, 2, 2, 0, 0], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (30) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[82], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_pred)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_test)\n\u001B[1;32m---> 15\u001B[0m mse \u001B[38;5;241m=\u001B[39m ((\u001B[43my_pred\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMean Squared Error:\u001B[39m\u001B[38;5;124m\"\u001B[39m, mse\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy())\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (3) must match the size of tensor b (30) at non-singleton dimension 1"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:21.927022Z",
     "start_time": "2024-05-14T11:17:21.927022Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "12a5a45e4c81ba44",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
